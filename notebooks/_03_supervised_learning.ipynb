{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6e7656",
   "metadata": {},
   "source": [
    "### ***`Supervised Machine Learning`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04db7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from functools import lru_cache\n",
    "from collections import Counter\n",
    "from datetime import datetime, timezone\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e21da37",
   "metadata": {},
   "source": [
    "##### `Reading modelpoints dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "732cb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads model points data from local directory\n",
    "def loading_modelpoint_data(file_name: str) -> pd.DataFrame:\n",
    "    path = (Path('.').cwd().parent / 'data/processed') / file_name\n",
    "    df = pd.read_parquet(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d899a7e",
   "metadata": {},
   "source": [
    "##### `Split data modelpoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7860e81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>target</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_item_lifestyle_rate</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>week_of_month</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>item_type_lifestyle</th>\n",
       "      <th>item_type_all</th>\n",
       "      <th>...</th>\n",
       "      <th>total_user_int_by_time_of_day</th>\n",
       "      <th>user_active_rate</th>\n",
       "      <th>active_mode_active</th>\n",
       "      <th>user_unique_segment</th>\n",
       "      <th>weekend_interaction_rate</th>\n",
       "      <th>segment</th>\n",
       "      <th>prev_user_int_freq</th>\n",
       "      <th>item_type_transact</th>\n",
       "      <th>screen_page_screen1</th>\n",
       "      <th>user_unique_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4521</td>\n",
       "      <td>click</td>\n",
       "      <td>ibab</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.307323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4521</td>\n",
       "      <td>checkout</td>\n",
       "      <td>ibab</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14454</td>\n",
       "      <td>click</td>\n",
       "      <td>cafm</td>\n",
       "      <td>0</td>\n",
       "      <td>4.338837e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14454</td>\n",
       "      <td>checkout</td>\n",
       "      <td>cafm</td>\n",
       "      <td>0</td>\n",
       "      <td>4.338837e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15000</td>\n",
       "      <td>click</td>\n",
       "      <td>carf</td>\n",
       "      <td>0</td>\n",
       "      <td>9.749279e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    target item_id  user_item_lifestyle_rate       day_sin  \\\n",
       "0     4521     click    ibab                         0 -2.449294e-16   \n",
       "1     4521  checkout    ibab                         0 -2.449294e-16   \n",
       "2    14454     click    cafm                         0  4.338837e-01   \n",
       "3    14454  checkout    cafm                         0  4.338837e-01   \n",
       "4    15000     click    carf                         0  9.749279e-01   \n",
       "\n",
       "   month_sin  week_of_month  is_month_start  item_type_lifestyle  \\\n",
       "0   0.866025              1               0                  0.0   \n",
       "1   0.866025              1               0                  0.0   \n",
       "2   0.866025              2               0                  0.0   \n",
       "3   0.866025              2               0                  0.0   \n",
       "4   0.500000              5               0                  0.0   \n",
       "\n",
       "   item_type_all  ...  total_user_int_by_time_of_day  user_active_rate  \\\n",
       "0            0.0  ...                              5                 0   \n",
       "1            0.0  ...                              5                 0   \n",
       "2            0.0  ...                              3                 1   \n",
       "3            0.0  ...                              3                 1   \n",
       "4            0.0  ...                              3                 0   \n",
       "\n",
       "   active_mode_active  user_unique_segment  weekend_interaction_rate  segment  \\\n",
       "0                 0.0                    1                       0.6        1   \n",
       "1                 0.0                    1                       0.6        1   \n",
       "2                 1.0                    1                       0.0        2   \n",
       "3                 1.0                    1                       0.0        2   \n",
       "4                 0.0                    1                       0.0        0   \n",
       "\n",
       "   prev_user_int_freq  item_type_transact  screen_page_screen1  \\\n",
       "0            0.307323                 0.0                  1.0   \n",
       "1            0.130420                 0.0                  1.0   \n",
       "2            0.228236                 1.0                  0.0   \n",
       "3            0.033729                 1.0                  0.0   \n",
       "4            0.307323                 0.0                  0.0   \n",
       "\n",
       "   user_unique_items  \n",
       "0                  2  \n",
       "1                  2  \n",
       "2                  2  \n",
       "3                  2  \n",
       "4                  2  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Modepoints\n",
    "modelpoint_train = loading_modelpoint_data('modelpoint_train.parquet')\n",
    "# modelpoint_train = modelpoint_train[modelpoint_train.item_id != 'no_item_id']\n",
    "modelpoint_eval = loading_modelpoint_data('modelpoint_eval.parquet')\n",
    "modelpoint_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "94e15b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Split\n",
    "# data_point_size = 20000\n",
    "# X_points = modelpoint_train.iloc[:data_point_size]\n",
    "X_points = modelpoint_train.copy()\n",
    "\n",
    "y = X_points['target']\n",
    "X = X_points.drop(columns=['target', 'item_id', 'user_id']).astype(float)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Target encoding\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd25f72d",
   "metadata": {},
   "source": [
    "### **`ML Experiments`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b11b9f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import signature\n",
    "from dataclasses import dataclass\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, cross_val_score\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    f1_score, accuracy_score, \n",
    "    roc_auc_score, classification_report\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a98d4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save model metadata into the local 'models' folder\n",
    "def save_model_and_metadata(model: ClassifierMixin, metadata: dict, classifier_name: str, version: float, report_df: pd.DataFrame):\n",
    "    file_directory = Path('.').cwd().parent / \"models/classifiers\"\n",
    "    file_directory.mkdir(exist_ok=True)\n",
    "\n",
    "    model_path = file_directory / f\"{classifier_name}_model_v{version}.pkl\"\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "    meta_path = file_directory / f\"{classifier_name}_metadata_v{version}.json\"\n",
    "    with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "\n",
    "    report_path = file_directory / f\"{classifier_name}_classifier_report_v{version}.csv\"\n",
    "    report_df.to_csv(report_path)\n",
    "\n",
    "    logger.info(f\"Saved model to: {model_path}\")\n",
    "    logger.info(f\"Saved metadata to: {meta_path}\")\n",
    "    logger.info(f\"Saved report classifier to: {report_path}\")\n",
    "\n",
    "    return model_path, meta_path, report_path\n",
    "\n",
    "# Extract model parameters (non-defaults)\n",
    "def model_non_default_params(model: BaseEstimator):\n",
    "    sig = signature(model.__class__.__init__)\n",
    "    defaults = {k: v.default for k, v in sig.parameters.items() if v.default is not v.empty}\n",
    "    current_params = model.get_params()\n",
    "    return {k: v for k, v in current_params.items() if k in defaults and v != defaults[k]}\n",
    "\n",
    "# Main model trainer\n",
    "@dataclass\n",
    "class ModelTrainer:\n",
    "    classifier: ClassifierMixin | BaseEstimator\n",
    "    X_train: np.ndarray | pd.DataFrame\n",
    "    X_test: np.ndarray | pd.DataFrame\n",
    "    y_train: np.ndarray | pd.Series\n",
    "    y_test: np.ndarray | pd.Series\n",
    "    data_size: int\n",
    "    version: float = 0.1\n",
    "    decimal: int = 3\n",
    "    \n",
    "    def train_model(self):\n",
    "        classifier_name = self.classifier.__class__.__name__.lower()\n",
    "        logger.info(f'Model training [{self.classifier.__class__.__name__.lower()}] started ... ')\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.classifier, self.X_train, self.y_train, cv=skf, scoring='f1_weighted')\n",
    "\n",
    "        print(f\"CV Weighted F1 scores: {cv_scores}\")\n",
    "        print(f\"Mean CV Weighted F1 score: {cv_scores.mean():.4f}\")\n",
    "\n",
    "        self.classifier.fit(self.X_train, self.y_train)\n",
    "        train_y_pred = self.classifier.predict(self.X_train)\n",
    "        train_y_pred_proba = self.classifier.predict_proba(self.X_train)[:, 1]\n",
    "        test_y_pred = self.classifier.predict(self.X_test)\n",
    "        test_y_pred_proba = self.classifier.predict_proba(self.X_test)[:, 1]\n",
    "\n",
    "        train_acc_score = accuracy_score(self.y_train, train_y_pred)\n",
    "        train_f_score = f1_score(self.y_train, train_y_pred, average='weighted')\n",
    "        train_ra_score = roc_auc_score(self.y_train, train_y_pred_proba)\n",
    "\n",
    "        test_acc_score = accuracy_score(self.y_test, test_y_pred)\n",
    "        test_f_score = f1_score(self.y_test, test_y_pred, average='weighted')\n",
    "        test_ra_score = roc_auc_score(self.y_test, test_y_pred_proba)\n",
    "\n",
    "        if hasattr(self.classifier, \"feature_importances_\"):\n",
    "            feature_names = self.X_train.columns if isinstance(self.X_train, pd.DataFrame) else np.arange(self.X_train.shape[1])\n",
    "            importances = self.classifier.feature_importances_\n",
    "            feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False)\n",
    "            \n",
    "            # Save to file\n",
    "            plt.style.use('ggplot')\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            top_n = 20\n",
    "            feat_imp.head(top_n).plot(kind='barh', title=f'Top {top_n} Feature Importances')\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.tight_layout()\n",
    "            file_img_path = f'{classifier_name}_top_feature_importances_v{self.version}.png'\n",
    "            plt.savefig(file_img_path, dpi=300)\n",
    "            plt.close()\n",
    "        else:\n",
    "            feat_imp = pd.Series()\n",
    "\n",
    "        report_dict = classification_report(self.y_test, test_y_pred, output_dict=True)\n",
    "        report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "        metadata =  {\n",
    "            'data_size': self.data_size, \n",
    "            'classifier': classifier_name,\n",
    "            'params': model_non_default_params(self.classifier),\n",
    "            'cv weighted f1': np.round(cv_scores.mean(), self.decimal),\n",
    "            'accuracy score': {'train': np.round(train_acc_score, self.decimal), 'test': np.round(test_acc_score, self.decimal)},\n",
    "            'weighted f1 score': {'train': np.round(train_f_score, self.decimal), 'test': np.round(test_f_score, self.decimal)},\n",
    "            'roc-auc score': {'train': np.round(train_ra_score, self.decimal), 'test': np.round(test_ra_score, self.decimal)},\n",
    "            'feature importance': feat_imp.to_dict() if not feat_imp.empty else {},\n",
    "        }\n",
    "        model_path, meta_path, report_path = save_model_and_metadata(self.classifier, metadata,classifier_name, self.version, report_df)\n",
    "\n",
    "        print(f\"\\nResults for {classifier_name}:\")\n",
    "        print(\"Accuracy Score:\", train_acc_score)\n",
    "        print(\"F1 Score:\", train_f_score)\n",
    "        print(\"Roc-Auc Score:\", train_ra_score)\n",
    "        print(classification_report(self.y_test, test_y_pred))\n",
    "\n",
    "        return {\n",
    "           **metadata,\n",
    "            'model path': model_path,\n",
    "            'metdata path': meta_path,\n",
    "            'report path': report_path\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bece6701",
   "metadata": {},
   "source": [
    "`Experiment on Different Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1468a11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 01:29:28,404 - INFO - Model training [logisticregression] started ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "CV Weighted F1 scores: [0.39255345 0.39259079 0.39257406 0.39257406 0.39257406]\n",
      "Mean CV Weighted F1 score: 0.3926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 01:29:34,886 - INFO - Saved model to: /mnt/d/research-workspace/workx-projects/fnb-dataquest-recosys/models/classifiers/logisticregression_model_v0.1.pkl\n",
      "2025-06-26 01:29:34,888 - INFO - Saved metadata to: /mnt/d/research-workspace/workx-projects/fnb-dataquest-recosys/models/classifiers/logisticregression_metadata_v0.1.json\n",
      "2025-06-26 01:29:34,892 - INFO - Saved report classifier to: /mnt/d/research-workspace/workx-projects/fnb-dataquest-recosys/models/classifiers/logisticregression_classifier_report_v0.1.csv\n",
      "2025-06-26 01:29:34,908 - INFO - Model training [randomforestclassifier] started ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for logisticregression:\n",
      "Accuracy Score: 0.5519260361263464\n",
      "F1 Score: 0.3925732828279465\n",
      "Roc-Auc Score: 0.5248555217904204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     17544\n",
      "           1       0.55      1.00      0.71     21611\n",
      "\n",
      "    accuracy                           0.55     39155\n",
      "   macro avg       0.28      0.50      0.36     39155\n",
      "weighted avg       0.30      0.55      0.39     39155\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "CV Weighted F1 scores: [0.60313432 0.60908946 0.60235925 0.60152152 0.6047266 ]\n",
      "Mean CV Weighted F1 score: 0.6042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 01:32:20,466 - INFO - Saved model to: /mnt/d/research-workspace/workx-projects/fnb-dataquest-recosys/models/classifiers/randomforestclassifier_model_v0.1.pkl\n",
      "2025-06-26 01:32:20,468 - INFO - Saved metadata to: /mnt/d/research-workspace/workx-projects/fnb-dataquest-recosys/models/classifiers/randomforestclassifier_metadata_v0.1.json\n",
      "2025-06-26 01:32:20,469 - INFO - Saved report classifier to: /mnt/d/research-workspace/workx-projects/fnb-dataquest-recosys/models/classifiers/randomforestclassifier_classifier_report_v0.1.csv\n",
      "2025-06-26 01:32:20,487 - INFO - Model training [xgbclassifier] started ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for randomforestclassifier:\n",
      "Accuracy Score: 0.6339222434346208\n",
      "F1 Score: 0.6271011851826916\n",
      "Roc-Auc Score: 0.7241420185692343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.78      0.64     17544\n",
      "           1       0.73      0.47      0.57     21611\n",
      "\n",
      "    accuracy                           0.61     39155\n",
      "   macro avg       0.64      0.63      0.61     39155\n",
      "weighted avg       0.64      0.61      0.60     39155\n",
      "\n",
      "\n",
      "Training XGBoost...\n",
      "CV Weighted F1 scores: [0.67072466 0.6654609  0.66655335 0.67047336 0.66687442]\n",
      "Mean CV Weighted F1 score: 0.6680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 01:32:36,560 - INFO - Saved model to: /mnt/d/research-workspace/workx-projects/fnb-dataquest-recosys/models/classifiers/xgbclassifier_model_v0.1.pkl\n",
      "2025-06-26 01:32:36,561 - INFO - Saved metadata to: /mnt/d/research-workspace/workx-projects/fnb-dataquest-recosys/models/classifiers/xgbclassifier_metadata_v0.1.json\n",
      "2025-06-26 01:32:36,563 - INFO - Saved report classifier to: /mnt/d/research-workspace/workx-projects/fnb-dataquest-recosys/models/classifiers/xgbclassifier_classifier_report_v0.1.csv\n",
      "2025-06-26 01:32:36,596 - INFO - Model training [lgbmclassifier] started ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for xgbclassifier:\n",
      "Accuracy Score: 0.7019161393718434\n",
      "F1 Score: 0.6996194950130216\n",
      "Roc-Auc Score: 0.7809618485153436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62     17544\n",
      "           1       0.69      0.75      0.72     21611\n",
      "\n",
      "    accuracy                           0.68     39155\n",
      "   macro avg       0.67      0.67      0.67     39155\n",
      "weighted avg       0.67      0.68      0.67     39155\n",
      "\n",
      "\n",
      "Training LightGBM...\n",
      "CV Weighted F1 scores: [0.6627169  0.66110156 0.66123664 0.66489927 0.66064478]\n",
      "Mean CV Weighted F1 score: 0.6621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 01:32:58,572 - INFO - Saved model to: /mnt/d/research-workspace/workx-projects/fnb-dataquest-recosys/models/classifiers/lgbmclassifier_model_v0.1.pkl\n",
      "2025-06-26 01:32:58,573 - INFO - Saved metadata to: /mnt/d/research-workspace/workx-projects/fnb-dataquest-recosys/models/classifiers/lgbmclassifier_metadata_v0.1.json\n",
      "2025-06-26 01:32:58,574 - INFO - Saved report classifier to: /mnt/d/research-workspace/workx-projects/fnb-dataquest-recosys/models/classifiers/lgbmclassifier_classifier_report_v0.1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for lgbmclassifier:\n",
      "Accuracy Score: 0.6858003920391784\n",
      "F1 Score: 0.6851509451257946\n",
      "Roc-Auc Score: 0.7737841049733397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.76      0.67     17544\n",
      "           1       0.75      0.59      0.66     21611\n",
      "\n",
      "    accuracy                           0.67     39155\n",
      "   macro avg       0.68      0.68      0.67     39155\n",
      "weighted avg       0.68      0.67      0.67     39155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare model performance metrics using Logistic Regression as the baseline\n",
    "seed = 43\n",
    "data_point_size = len(modelpoint_train)\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=100, random_state=seed),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, max_depth=10, class_weight='balanced', random_state=seed),\n",
    "    'XGBoost': XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=6, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=200, learning_rate=0.1, class_weight='balanced', random_state=seed, verbosity=-1)\n",
    "}\n",
    "\n",
    "# Train, predict, and evaluate\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model_trainer = ModelTrainer(model, X_train, X_test, y_train_enc, y_test_enc, data_point_size, version=0.1)\n",
    "    trainer = model_trainer.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a68dac",
   "metadata": {},
   "source": [
    "`HyperTuning Best Classifier (Optuna)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d3d4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Define Optuna objective\n",
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "#         'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "#     }\n",
    "#     model = LGBMClassifier(**params, random_state=42, class_weight='balanced', verbosity=-1, n_jobs=-1)\n",
    "#     kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "#     scores = []\n",
    "#     for train_idx, val_idx in kf.split(X_train, y_train):\n",
    "#         model.fit(X_train.iloc[train_idx], y_train.iloc[train_idx])\n",
    "#         preds = model.predict(X_train.iloc[val_idx])\n",
    "#         scores.append(f1_score(y_train.iloc[val_idx], preds, average='weighted'))\n",
    "#     return np.mean(scores)\n",
    "\n",
    "# # Run optimization\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=100)\n",
    "\n",
    "# # study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457c1cc",
   "metadata": {},
   "source": [
    "`Retraining With Tune-params`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "669adf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = study.best_params\n",
    "# model = LGBMClassifier(**params, random_state=42, class_weight='balanced', verbosity=-1, n_jobs=-1)\n",
    "# model_trainer = ModelTrainer(model, X_train, X_test, y_train_enc, y_test_enc, version=0.6)\n",
    "# trainer = model_trainer.train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
